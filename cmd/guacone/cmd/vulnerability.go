//
// Copyright 2023 The GUAC Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package cmd

import (
	"context"
	"fmt"
	"net/http"
	"os"
	"strings"
	"sync"

	"github.com/Khan/genqlient/graphql"
	model "github.com/guacsec/guac/pkg/assembler/clients/generated"
	"github.com/guacsec/guac/pkg/assembler/helpers"
	"github.com/guacsec/guac/pkg/cli"
	"github.com/guacsec/guac/pkg/logging"
	"github.com/guacsec/guac/pkg/misc/depversion"
	"github.com/jedib0t/go-pretty/v6/table"
	"github.com/spf13/cobra"
	"github.com/spf13/viper"
)

const (
	guacType   string = "guac"
	noVulnType string = "novuln"
)

type queryOptions struct {
	// gql endpoint
	graphqlEndpoint string

	searchString    string
	isPurl          bool
	vulnerabilityID string
	depth           int
	pathsToReturn   int
}

var queryVulnCmd = &cobra.Command{
	Use:   "vuln [flags] <purl/sbomURI>",
	Short: "query if a package is affected by the specified vulnerability",
	Run: func(cmd *cobra.Command, args []string) {
		ctx := logging.WithLogger(context.Background())

		opts, err := validateQueryVulnFlags(
			viper.GetString("gql-addr"),
			viper.GetString("vuln-id"),
			viper.GetInt("search-depth"),
			viper.GetInt("num-path"),
			args,
		)

		if err != nil {
			fmt.Printf("unable to validate flags: %v\n", err)
			_ = cmd.Help()
			os.Exit(1)
		}

		httpClient := http.Client{}
		gqlclient := graphql.NewClient(opts.graphqlEndpoint, &httpClient)

		t := table.NewWriter()
		tTemp := table.Table{}
		tTemp.Render()
		t.AppendHeader(rowHeader)

		if opts.vulnerabilityID != "" {
			printVulnInfoByVulnId(ctx, gqlclient, t, opts)
		} else {
			printVulnInfo(ctx, gqlclient, t, opts)
		}
	},
}

func getPkgResponseFromPurl(ctx context.Context, gqlclient graphql.Client, purl string) (*model.PackagesResponse, error) {
	pkgInput, err := helpers.PurlToPkg(purl)
	if err != nil {
		return nil, fmt.Errorf("failed to parse PURL: %v", err)
	}

	pkgQualifierFilter := []model.PackageQualifierSpec{}
	for _, qualifier := range pkgInput.Qualifiers {
		pkgQualifierFilter = append(pkgQualifierFilter, model.PackageQualifierSpec{
			Key:   qualifier.Key,
			Value: &qualifier.Value,
		})
	}

	pkgFilter := &model.PkgSpec{
		Type:       &pkgInput.Type,
		Namespace:  pkgInput.Namespace,
		Name:       &pkgInput.Name,
		Version:    pkgInput.Version,
		Subpath:    pkgInput.Subpath,
		Qualifiers: pkgQualifierFilter,
	}
	pkgResponse, err := model.Packages(ctx, gqlclient, *pkgFilter)
	if err != nil {
		return nil, fmt.Errorf("error querying for package: %v", err)
	}
	if len(pkgResponse.Packages) != 1 {
		return nil, fmt.Errorf("failed to located package based on purl")
	}
	return pkgResponse, nil
}

func printVulnInfo(ctx context.Context, gqlclient graphql.Client, t table.Writer, opts queryOptions) {
	logger := logging.FromContext(ctx)
	var path []string
	var tableRows []table.Row

	depVulnPath, depVulnTableRows, err := searchPkgViaHasSBOM(ctx, gqlclient, opts.searchString, opts.depth, opts.isPurl)
	if err != nil {
		logger.Fatalf("error searching via hasSBOM: %v", err)
	}
	path = append(path, depVulnPath...)
	tableRows = append(tableRows, depVulnTableRows...)

	if len(path) > 0 {
		t.AppendRows(tableRows)

		fmt.Println(t.Render())
		fmt.Printf("Visualizer url: http://localhost:3000/?path=%v\n", strings.Join(removeDuplicateValuesFromPath(path), `,`))
	} else {
		fmt.Printf("No path to vulnerabilities found!\n")
	}
}

func printVulnInfoByVulnId(ctx context.Context, gqlclient graphql.Client, t table.Writer, opts queryOptions) {
	logger := logging.FromContext(ctx)
	var tableRows []table.Row

	vulnResponse, err := model.Vulnerabilities(ctx, gqlclient, model.VulnerabilitySpec{VulnerabilityID: &opts.vulnerabilityID})
	if err != nil {
		logger.Fatalf("error querying for vulnerabilities: %v", err)
	}

	if len(vulnResponse.Vulnerabilities) == 0 {
		fmt.Printf("Failed to identify vulnerability \n")
		return
	}
	var path []string

	if opts.isPurl {
		pkgResponse, err := getPkgResponseFromPurl(ctx, gqlclient, opts.searchString)
		if err != nil {
			logger.Fatalf("getPkgResponseFromPurl - error: %v", err)
		}
		path, tableRows, err = queryVulnsViaVulnNodeNeighbors(ctx, gqlclient, pkgResponse.Packages[0].Namespaces[0].Names[0].Versions[0].Id, vulnResponse.Vulnerabilities, opts.depth, opts.pathsToReturn)
		if err != nil {
			logger.Fatalf("error querying neighbor: %v", err)
		}
	} else {
		foundHasSBOMPkg, err := model.HasSBOMs(ctx, gqlclient, model.HasSBOMSpec{Uri: &opts.searchString})
		if err != nil {
			logger.Fatalf("failed getting hasSBOM via URI: %s with error: %w", opts.searchString, err)
		}
		if len(foundHasSBOMPkg.HasSBOM) != 1 {
			logger.Fatalf("failed to located singular hasSBOM based on URI")
		}
		if pkgResponse, ok := foundHasSBOMPkg.HasSBOM[0].Subject.(*model.AllHasSBOMTreeSubjectPackage); ok {
			path, tableRows, err = queryVulnsViaVulnNodeNeighbors(ctx, gqlclient, pkgResponse.Namespaces[0].Names[0].Versions[0].Id, vulnResponse.Vulnerabilities, opts.depth, opts.pathsToReturn)
			if err != nil {
				logger.Fatalf("error querying neighbor: %v", err)
			}
		} else {
			logger.Fatalf("located hasSBOM does not have a subject that is a package")
		}
	}
	if len(path) > 0 {
		t.AppendRows(tableRows)
		fmt.Println(t.Render())
		fmt.Printf("Visualizer url: http://localhost:3000/?path=%v\n", strings.Join(removeDuplicateValuesFromPath(path), `,`))
	} else {
		fmt.Printf("No path to vulnerability ID found!\n")
	}
}

func queryVulnsViaPackageNeighbors(ctx context.Context, gqlclient graphql.Client, pkgVersionID string) ([]string, []table.Row, error) {
	var path []string
	var tableRows []table.Row
	var edgeTypes = []model.Edge{model.EdgePackageCertifyVuln, model.EdgePackageCertifyVexStatement}

	pkgVersionNeighborResponse, err := model.Neighbors(ctx, gqlclient, pkgVersionID, edgeTypes)
	if err != nil {
		return nil, nil, fmt.Errorf("error querying neighbor for vulnerability: %w", err)
	}
	certifyVulnFound := false
	for _, neighbor := range pkgVersionNeighborResponse.Neighbors {
		if certifyVuln, ok := neighbor.(*model.NeighborsNeighborsCertifyVuln); ok {
			certifyVulnFound = true
			if certifyVuln.Vulnerability.Type != noVulnType {
				for _, vuln := range certifyVuln.Vulnerability.VulnerabilityIDs {
					tableRows = append(tableRows, table.Row{certifyVulnStr, certifyVuln.Id, "vulnerability ID: " + vuln.VulnerabilityID})
					path = append(path, []string{vuln.Id, certifyVuln.Id,
						certifyVuln.Package.Namespaces[0].Names[0].Versions[0].Id,
						certifyVuln.Package.Namespaces[0].Names[0].Id, certifyVuln.Package.Namespaces[0].Id,
						certifyVuln.Package.Id}...)
				}
			}
		}

		if certifyVex, ok := neighbor.(*model.NeighborsNeighborsCertifyVEXStatement); ok {
			for _, vuln := range certifyVex.Vulnerability.VulnerabilityIDs {
				tableRows = append(tableRows, table.Row{vexLinkStr, certifyVex.Id, "vulnerability ID: " + vuln.VulnerabilityID + ", Vex Status: " + string(certifyVex.Status) + ", Subject: " + vexSubjectString(certifyVex.Subject)})
				path = append(path, certifyVex.Id, vuln.Id)
			}
			path = append(path, vexSubjectIds(certifyVex.Subject)...)
		}

	}
	if !certifyVulnFound {
		return nil, nil, fmt.Errorf("error certify vulnerability node not found, incomplete data. Please ensure certifier has run")
	}
	return path, tableRows, nil
}

func vexSubjectString(s model.AllCertifyVEXStatementSubjectPackageOrArtifact) string {
	switch v := s.(type) {
	case *model.AllCertifyVEXStatementSubjectArtifact:
		return fmt.Sprintf("artifact (id:%v) %v:%v", v.Id, v.Algorithm, v.Digest)
	case *model.AllCertifyVEXStatementSubjectPackage:
		return fmt.Sprintf("package (id:%v) %v:%v/%v@%v",
			v.Id,
			v.Type,
			v.Namespaces[0].Namespace,
			v.Namespaces[0].Names[0].Name,
			v.Namespaces[0].Names[0].Versions[0].Version)
	default:
		return "unknown subject"
	}
}
func vexSubjectIds(s model.AllCertifyVEXStatementSubjectPackageOrArtifact) []string {
	switch v := s.(type) {
	case *model.AllCertifyVEXStatementSubjectArtifact:
		return []string{v.Id}
	case *model.AllCertifyVEXStatementSubjectPackage:
		return []string{
			v.Id,
			v.Namespaces[0].Id,
			v.Namespaces[0].Names[0].Id,
			v.Namespaces[0].Names[0].Versions[0].Id}
	default:
		return []string{}
	}
}

func queryVulnsViaVulnNodeNeighbors(ctx context.Context, gqlclient graphql.Client, topPkgVersionID string, vulnerabilitiesResponses []model.VulnerabilitiesVulnerabilitiesVulnerability, depth int, pathsToReturn int) ([]string, []table.Row, error) {
	type vulnNeighbor struct {
		node model.NeighborsNeighborsNode
		id   string
	}

	var path []string
	var vulnNodeNeighborResponses []vulnNeighbor
	var tableRows []table.Row

	edgeTypes := []model.Edge{model.EdgeVulnerabilityCertifyVuln, model.EdgeVulnerabilityCertifyVexStatement}
	for _, vulnerabilitiesResponse := range vulnerabilitiesResponses {
		for _, vulnerabilityNodeID := range vulnerabilitiesResponse.VulnerabilityIDs {
			vulnNodeNeighborResponse, err := model.Neighbors(ctx, gqlclient, vulnerabilityNodeID.Id, edgeTypes)
			if err != nil {
				return nil, nil, fmt.Errorf("error querying neighbor for vulnerability: %w", err)
			}
			for _, neighbor := range vulnNodeNeighborResponse.Neighbors {
				vulnNodeNeighborResponses = append(vulnNodeNeighborResponses, vulnNeighbor{neighbor, vulnerabilityNodeID.Id})
			}
		}
	}

	certifyVulnFound := false
	numberOfPaths := 0
	for _, neighbor := range vulnNodeNeighborResponses {
		if certifyVuln, ok := neighbor.node.(*model.NeighborsNeighborsCertifyVuln); ok {
			certifyVulnFound = true
			pkgPath, err := searchDependencyPackagesReverse(ctx, gqlclient, topPkgVersionID, certifyVuln.Package.Namespaces[0].Names[0].Versions[0].Id, depth)
			if err != nil {
				return nil, nil, fmt.Errorf("error searching dependency packages match: %w", err)
			}
			if len(pkgPath) > 0 {
				tableRows = append(tableRows, table.Row{certifyVulnStr, certifyVuln.Id, "vulnerability ID: " + certifyVuln.Vulnerability.VulnerabilityIDs[0].VulnerabilityID})
				fullVulnPath := append([]string{certifyVuln.Vulnerability.Id, certifyVuln.Vulnerability.VulnerabilityIDs[0].Id, certifyVuln.Id,
					certifyVuln.Package.Namespaces[0].Names[0].Versions[0].Id,
					certifyVuln.Package.Namespaces[0].Names[0].Id, certifyVuln.Package.Namespaces[0].Id,
					certifyVuln.Package.Id}, pkgPath...)
				path = append(path, fullVulnPath...)
				numberOfPaths += 1
			}
			if pathsToReturn != 0 && numberOfPaths == pathsToReturn {
				return path, nil, nil
			}
		}
		if certifyVex, ok := neighbor.node.(*model.NeighborsNeighborsCertifyVEXStatement); ok {
			certifyVulnFound = true
			for _, vuln := range certifyVex.Vulnerability.VulnerabilityIDs {
				tableRows = append(tableRows, table.Row{vexLinkStr, certifyVex.Id, "vulnerability ID: " + vuln.VulnerabilityID + ", Vex Status: " + string(certifyVex.Status) + ", Subject: " + vexSubjectString(certifyVex.Subject)})
				path = append(path, certifyVex.Id, vuln.Id)
			}
			path = append(path, vexSubjectIds(certifyVex.Subject)...)
		}
	}
	if !certifyVulnFound {
		return nil, nil, fmt.Errorf("error certify vulnerability node not found, incomplete data. Please ensure certifier has run")
	}
	return path, tableRows, nil
}

func searchDependencyPackagesReverse(ctx context.Context, gqlclient graphql.Client, topPkgID string, searchPkgID string, maxLength int) ([]string, error) {
	var path []string
	var collectedIDs []string
	queue := make([]string, 0) // the queue of nodes in bfs
	type dfsNode struct {
		expanded     bool // true once all node neighbors are added to queue
		parent       string
		isDependency *model.NeighborsNeighborsIsDependency
		depth        int
	}
	nodeMap := map[string]dfsNode{}

	nodeMap[searchPkgID] = dfsNode{}
	queue = append(queue, searchPkgID)
	collectedIDs = append(collectedIDs, searchPkgID)

	found := false
	for len(queue) > 0 {
		now := queue[0]
		queue = queue[1:]
		nowNode := nodeMap[now]

		if topPkgID != "" {
			if now == topPkgID {
				found = true
				break
			}
		}

		if maxLength != 0 && nowNode.depth >= maxLength {
			break
		}

		isDependencyNeighborResponses, err := model.Neighbors(ctx, gqlclient, now, []model.Edge{model.EdgePackageIsDependency})
		if err != nil {
			return nil, fmt.Errorf("failed getting package parent:%v", err)
		}
		for _, neighbor := range isDependencyNeighborResponses.Neighbors {
			if isDependency, ok := neighbor.(*model.NeighborsNeighborsIsDependency); ok && now != isDependency.Package.Namespaces[0].Names[0].Versions[0].Id {
				dfsN, seen := nodeMap[isDependency.Package.Namespaces[0].Names[0].Versions[0].Id]
				if !seen {
					dfsN = dfsNode{
						parent:       now,
						isDependency: isDependency,
						depth:        nowNode.depth + 1,
					}
					nodeMap[isDependency.Package.Namespaces[0].Names[0].Versions[0].Id] = dfsN
				}
				if !dfsN.expanded {
					queue = append(queue, isDependency.Package.Namespaces[0].Names[0].Versions[0].Id)
					collectedIDs = append(collectedIDs, isDependency.Package.Namespaces[0].Names[0].Versions[0].Id)
				}
			}
		}
		nowNode.expanded = true
		nodeMap[now] = nowNode
	}

	if topPkgID != "" && !found {
		return nil, fmt.Errorf("no path found up to specified length")
	}

	var now string
	if topPkgID != "" {
		now = topPkgID
		for now != searchPkgID {
			if len(nodeMap[now].isDependency.DependencyPackage.Namespaces[0].Names[0].Versions) > 0 {
				path = append(path, nodeMap[now].isDependency.Id, nodeMap[now].isDependency.DependencyPackage.Namespaces[0].Names[0].Versions[0].Id,
					nodeMap[now].isDependency.DependencyPackage.Namespaces[0].Names[0].Id,
					nodeMap[now].isDependency.DependencyPackage.Namespaces[0].Id, nodeMap[now].isDependency.DependencyPackage.Id,
					nodeMap[now].isDependency.Package.Namespaces[0].Names[0].Versions[0].Id,
					nodeMap[now].isDependency.Package.Namespaces[0].Names[0].Id, nodeMap[now].isDependency.Package.Namespaces[0].Id,
					nodeMap[now].isDependency.Package.Id)
			} else {
				path = append(path, nodeMap[now].isDependency.Id, nodeMap[now].isDependency.DependencyPackage.Namespaces[0].Names[0].Id,
					nodeMap[now].isDependency.DependencyPackage.Namespaces[0].Id, nodeMap[now].isDependency.DependencyPackage.Id,
					nodeMap[now].isDependency.Package.Namespaces[0].Names[0].Versions[0].Id,
					nodeMap[now].isDependency.Package.Namespaces[0].Names[0].Id, nodeMap[now].isDependency.Package.Namespaces[0].Id,
					nodeMap[now].isDependency.Package.Id)
			}

			now = nodeMap[now].parent
		}
		return path, nil
	} else {
		for i := len(collectedIDs) - 1; i >= 0; i-- {
			if nodeMap[collectedIDs[i]].isDependency != nil {
				if len(nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Namespaces[0].Names[0].Versions) > 0 {
					path = append(path, nodeMap[collectedIDs[i]].isDependency.Id, nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Namespaces[0].Names[0].Versions[0].Id,
						nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Namespaces[0].Names[0].Id,
						nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Namespaces[0].Id, nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Id,
						nodeMap[collectedIDs[i]].isDependency.Package.Namespaces[0].Names[0].Versions[0].Id,
						nodeMap[collectedIDs[i]].isDependency.Package.Namespaces[0].Names[0].Id, nodeMap[collectedIDs[i]].isDependency.Package.Namespaces[0].Id,
						nodeMap[collectedIDs[i]].isDependency.Package.Id)
				} else {
					path = append(path, nodeMap[collectedIDs[i]].isDependency.Id, nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Namespaces[0].Names[0].Id,
						nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Namespaces[0].Id, nodeMap[collectedIDs[i]].isDependency.DependencyPackage.Id,
						nodeMap[collectedIDs[i]].isDependency.Package.Namespaces[0].Names[0].Versions[0].Id,
						nodeMap[collectedIDs[i]].isDependency.Package.Namespaces[0].Names[0].Id, nodeMap[collectedIDs[i]].isDependency.Package.Namespaces[0].Id,
						nodeMap[collectedIDs[i]].isDependency.Package.Id)
				}
			}
		}
		return path, nil
	}
}

func concurrentVulnAndVexNeighbors(ctx context.Context, gqlclient graphql.Client, pkgID string, isDep model.AllHasSBOMTreeIncludedDependenciesIsDependency, resultChan chan<- struct {
	pkgVersionNeighborResponse *model.NeighborsResponse
	isDep                      model.AllHasSBOMTreeIncludedDependenciesIsDependency
}, wg *sync.WaitGroup) {
	defer wg.Done()

	logger := logging.FromContext(ctx)
	pkgVersionNeighborResponse, err := model.Neighbors(ctx, gqlclient, pkgID, []model.Edge{model.EdgePackageCertifyVuln, model.EdgePackageCertifyVexStatement})
	if err != nil {
		logger.Errorf("error querying neighbor for vulnerability: %w", err)
		return
	}

	// Send the results to the resultChan
	resultChan <- struct {
		pkgVersionNeighborResponse *model.NeighborsResponse
		isDep                      model.AllHasSBOMTreeIncludedDependenciesIsDependency
	}{pkgVersionNeighborResponse, isDep}
}

// searchPkgViaHasSBOM takes in either a purl or URI for the initial value to find the hasSBOM node.
// From there is recursively searches through all the dependencies to determine if it contains hasSBOM nodes.
// It concurrent checks the package version node if it contains vulnerabilities and VEX data.
func searchPkgViaHasSBOM(ctx context.Context, gqlclient graphql.Client, searchString string, maxLength int, isPurl bool) ([]string, []table.Row, error) {
	var path []string
	var tableRows []table.Row
	checkedPkgIDs := make(map[string]bool)
	var wg sync.WaitGroup

	queue := make([]string, 0) // the queue of nodes in bfs
	type dfsNode struct {
		expanded bool // true once all node neighbors are added to queue
		parent   string
		pkgID    string
		depth    int
	}
	nodeMap := map[string]dfsNode{}

	nodeMap[searchString] = dfsNode{}
	queue = append(queue, searchString)

	resultChan := make(chan struct {
		pkgVersionNeighborResponse *model.NeighborsResponse
		isDep                      model.AllHasSBOMTreeIncludedDependenciesIsDependency
	})

	for len(queue) > 0 {
		now := queue[0]
		queue = queue[1:]
		nowNode := nodeMap[now]

		if maxLength != 0 && nowNode.depth >= maxLength {
			break
		}

		var foundHasSBOMPkg *model.HasSBOMsResponse
		var err error

		// if the initial depth, check if its a purl or an SBOM URI. Otherwise always search by pkgID
		if nowNode.depth == 0 {
			if isPurl {
				pkgResponse, err := getPkgResponseFromPurl(ctx, gqlclient, now)
				if err != nil {
					return nil, nil, fmt.Errorf("getPkgResponseFromPurl - error: %v", err)
				}
				foundHasSBOMPkg, err = model.HasSBOMs(ctx, gqlclient, model.HasSBOMSpec{Subject: &model.PackageOrArtifactSpec{Package: &model.PkgSpec{Id: &pkgResponse.Packages[0].Namespaces[0].Names[0].Versions[0].Id}}})
				if err != nil {
					return nil, nil, fmt.Errorf("failed getting hasSBOM via purl: %s with error :%w", now, err)
				}
			} else {
				foundHasSBOMPkg, err = model.HasSBOMs(ctx, gqlclient, model.HasSBOMSpec{Uri: &now})
				if err != nil {
					return nil, nil, fmt.Errorf("failed getting hasSBOM via URI: %s with error: %w", now, err)
				}
			}
		} else {
			foundHasSBOMPkg, err = model.HasSBOMs(ctx, gqlclient, model.HasSBOMSpec{Subject: &model.PackageOrArtifactSpec{Package: &model.PkgSpec{Id: &now}}})
			if err != nil {
				return nil, nil, fmt.Errorf("failed getting hasSBOM via purl: %s with error :%w", now, err)
			}
		}

		for _, hasSBOM := range foundHasSBOMPkg.HasSBOM {
			if pkgResponse, ok := foundHasSBOMPkg.HasSBOM[0].Subject.(*model.AllHasSBOMTreeSubjectPackage); ok {
				if pkgResponse.Type != guacType {
					if !checkedPkgIDs[pkgResponse.Namespaces[0].Names[0].Versions[0].Id] {
						vulnPath, pkgVulnTableRows, err := queryVulnsViaPackageNeighbors(ctx, gqlclient, pkgResponse.Namespaces[0].Names[0].Versions[0].Id)
						if err != nil {
							return nil, nil, fmt.Errorf("error querying neighbor: %v", err)
						}
						path = append(path, vulnPath...)
						tableRows = append(tableRows, pkgVulnTableRows...)
						path = append([]string{pkgResponse.Namespaces[0].Names[0].Versions[0].Id,
							pkgResponse.Namespaces[0].Names[0].Id, pkgResponse.Namespaces[0].Id,
							pkgResponse.Id}, path...)
						checkedPkgIDs[pkgResponse.Namespaces[0].Names[0].Versions[0].Id] = true
					}
				}
			}
			for _, isDep := range hasSBOM.IncludedDependencies {
				if isDep.DependencyPackage.Type == guacType {
					continue
				}
				var matchingDepPkgVersionIDs []string
				if len(isDep.DependencyPackage.Namespaces[0].Names[0].Versions) == 0 {
					findMatchingDepPkgVersionIDs, err := findDepPkgVersionIDs(ctx, gqlclient, isDep.DependencyPackage.Type, isDep.DependencyPackage.Namespaces[0].Namespace,
						isDep.DependencyPackage.Namespaces[0].Names[0].Name, isDep.VersionRange)
					if err != nil {
						return nil, nil, fmt.Errorf("error from findMatchingDepPkgVersionIDs:%w", err)
					}
					matchingDepPkgVersionIDs = append(matchingDepPkgVersionIDs, findMatchingDepPkgVersionIDs...)
				} else {
					matchingDepPkgVersionIDs = append(matchingDepPkgVersionIDs, isDep.DependencyPackage.Namespaces[0].Names[0].Versions[0].Id)
				}
				for _, pkgID := range matchingDepPkgVersionIDs {
					dfsN, seen := nodeMap[pkgID]
					if !seen {
						dfsN = dfsNode{
							parent: now,
							pkgID:  pkgID,
							depth:  nowNode.depth + 1,
						}
						nodeMap[pkgID] = dfsN
					}
					if !dfsN.expanded {
						queue = append(queue, pkgID)
					}
					wg.Add(1)
					go concurrentVulnAndVexNeighbors(ctx, gqlclient, pkgID, isDep, resultChan, &wg)
					checkedPkgIDs[pkgID] = true
				}
			}
		}
		nowNode.expanded = true
		nodeMap[now] = nowNode
	}

	// Close the result channel once all goroutines are done
	go func() {
		wg.Wait()
		close(resultChan)
	}()

	checkedCertifyVulnIDs := make(map[string]bool)

	// Collect results from the channel
	for result := range resultChan {
		for _, neighbor := range result.pkgVersionNeighborResponse.Neighbors {
			if certifyVuln, ok := neighbor.(*model.NeighborsNeighborsCertifyVuln); ok {
				if !checkedCertifyVulnIDs[certifyVuln.Id] {
					if certifyVuln.Vulnerability.Type != noVulnType {
						checkedCertifyVulnIDs[certifyVuln.Id] = true
						for _, vuln := range certifyVuln.Vulnerability.VulnerabilityIDs {
							tableRows = append(tableRows, table.Row{certifyVulnStr, certifyVuln.Id, "vulnerability ID: " + vuln.VulnerabilityID})
							path = append(path, []string{vuln.Id, certifyVuln.Id,
								certifyVuln.Package.Namespaces[0].Names[0].Versions[0].Id,
								certifyVuln.Package.Namespaces[0].Names[0].Id, certifyVuln.Package.Namespaces[0].Id,
								certifyVuln.Package.Id}...)
						}
						path = append(path, result.isDep.Id, result.isDep.Package.Namespaces[0].Names[0].Versions[0].Id,
							result.isDep.Package.Namespaces[0].Names[0].Id, result.isDep.Package.Namespaces[0].Id,
							result.isDep.Package.Id)
					}
				}
			}

			if certifyVex, ok := neighbor.(*model.NeighborsNeighborsCertifyVEXStatement); ok {
				for _, vuln := range certifyVex.Vulnerability.VulnerabilityIDs {
					tableRows = append(tableRows, table.Row{vexLinkStr, certifyVex.Id, "vulnerability ID: " + vuln.VulnerabilityID + ", Vex Status: " + string(certifyVex.Status) + ", Subject: " + vexSubjectString(certifyVex.Subject)})
					path = append(path, certifyVex.Id, vuln.Id)
				}
				path = append(path, vexSubjectIds(certifyVex.Subject)...)
			}
		}
	}
	return path, tableRows, nil
}

func findDepPkgVersionIDs(ctx context.Context, gqlclient graphql.Client, depPkgType string, depPkgNameSpace string, depPkgName string, versionRange string) ([]string, error) {
	var matchingDepPkgVersionIDs []string

	depPkgFilter := &model.PkgSpec{
		Type:      &depPkgType,
		Namespace: &depPkgNameSpace,
		Name:      &depPkgName,
	}

	depPkgResponse, err := model.Packages(ctx, gqlclient, *depPkgFilter)
	if err != nil {
		return nil, fmt.Errorf("error querying for dependent package: %w", err)
	}

	depPkgVersionsMap := map[string]string{}
	depPkgVersions := []string{}
	for _, depPkgVersion := range depPkgResponse.Packages[0].Namespaces[0].Names[0].Versions {
		depPkgVersions = append(depPkgVersions, depPkgVersion.Version)
		depPkgVersionsMap[depPkgVersion.Version] = depPkgVersion.Id
	}

	matchingDepPkgVersions, err := depversion.WhichVersionMatches(depPkgVersions, versionRange)
	if err != nil {
		// TODO(jeffmendoza): depversion is not handling all/new possible
		// version ranges from deps.dev. Continue here to report possible
		// vulns even if some paths cannot be followed.
		matchingDepPkgVersions = nil
		//return nil, nil, fmt.Errorf("error determining dependent version matches: %w", err)
	}

	for matchingDepPkgVersion := range matchingDepPkgVersions {
		matchingDepPkgVersionIDs = append(matchingDepPkgVersionIDs, depPkgVersionsMap[matchingDepPkgVersion])
	}
	return matchingDepPkgVersionIDs, nil
}

func removeDuplicateValuesFromPath(path []string) []string {
	keys := make(map[string]bool)
	var list []string

	for _, entry := range path {
		if _, value := keys[entry]; !value {
			keys[entry] = true
			list = append(list, entry)
		}
	}
	return list
}

func validateQueryVulnFlags(graphqlEndpoint, vulnID string, depth, path int, args []string) (queryOptions, error) {
	var opts queryOptions
	opts.graphqlEndpoint = graphqlEndpoint
	opts.vulnerabilityID = vulnID
	opts.depth = depth
	opts.pathsToReturn = path

	if len(args) > 0 {
		_, err := helpers.PurlToPkg(args[0])
		if err != nil {
			opts.isPurl = false
		} else {
			opts.isPurl = true
		}
		opts.searchString = args[0]
	} else {
		return opts, fmt.Errorf("expected subject input to be purl or SBOM URI")
	}
	return opts, nil
}

func init() {
	set, err := cli.BuildFlags([]string{"vuln-id", "search-depth", "num-path"})
	if err != nil {
		fmt.Fprintf(os.Stderr, "failed to setup flag: %v", err)
		os.Exit(1)
	}
	queryVulnCmd.Flags().AddFlagSet(set)
	if err := viper.BindPFlags(queryVulnCmd.Flags()); err != nil {
		fmt.Fprintf(os.Stderr, "failed to bind flags: %v", err)
		os.Exit(1)
	}

	queryCmd.AddCommand(queryVulnCmd)
}
